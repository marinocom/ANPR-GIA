{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from PIL import Image, ImageDraw, ImageOps\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
    "\n",
    "# Segment function updated to use the trained model for character recognition\n",
    "def segment(\n",
    "\t\t\tsource: List[List[Image.Image]]\n",
    "\t) -> Tuple[List[List[List[Image.Image]]], List[List[List[Image.Image]]], List[List[List[Tuple[Image.Image, str]]]]]:\n",
    "\t\"\"\"\n",
    "\tSegment the license plates into individual characters and visualize bounding boxes.\n",
    "\n",
    "\t:param source: Output of the extract_boxes function\n",
    "\t:return: Segments of license plates, visualizations of detected bounding boxes before and after filtering, and final segments with recognized characters.\n",
    "\t\"\"\"\n",
    "\tsegments = []\n",
    "\tvisualizations = []\n",
    "\trecognized_characters = []\n",
    "\n",
    "\tfor img in source:\n",
    "\t\timg_segments = []\n",
    "\t\timg_visualizations = []\n",
    "\t\timg_recognized = []\n",
    "\t\tfor plate in img:\n",
    "\t\t\tplate_segments = []\n",
    "\t\t\tplate_visualizations = []\n",
    "\t\t\tplate_recognized = []\n",
    "\t\t\t\n",
    "\t\t\t# Resize the plate to a consistent size\n",
    "\t\t\tplate = plate.resize((200, 50))\n",
    "\t\t\t\n",
    "\t\t\t# Convert to grayscale if not already\n",
    "\t\t\tif plate.mode != \"L\":\n",
    "\t\t\t\tgray = plate.convert(\"L\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tgray = plate.copy()\n",
    "\t\t\tgray = np.array(gray)\n",
    "\t\t\t\n",
    "\t\t\t# Preprocess using adaptive thresholding\n",
    "\t\t\tblurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\t\t\tthresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "\t\t\t\n",
    "\t\t\t# Invert the thresholded image to ensure white text on black background\n",
    "\t\t\tthresh = cv2.bitwise_not(thresh)\n",
    "\t\t\t\n",
    "\t\t\t# Find contours\n",
    "\t\t\tcontours, hierarchy = cv2.findContours(thresh, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\t\t\thierarchy = hierarchy[0]\n",
    "\t\t\t\n",
    "\t\t\t# Create an initial visualization with all bounding boxes\n",
    "\t\t\toriginal_visualization = plate.convert(\"RGB\")\n",
    "\t\t\tdraw = ImageDraw.Draw(original_visualization)\n",
    "\t\t\tfor contour in contours:\n",
    "\t\t\t\tx, y, w, h = cv2.boundingRect(contour)\n",
    "\t\t\t\tdraw.rectangle([x, y, x + w, y + h], outline=\"red\", width=1)\n",
    "\t\t\tplate_visualizations.append(original_visualization)\n",
    "\t\t\t\n",
    "\t\t\t# Filter contours to remove obvious noise, but retain characters and possible extra regions\n",
    "\t\t\tbounding_boxes = []\n",
    "\t\t\tfor i, contour in enumerate(contours):\n",
    "\t\t\t\tx, y, w, h = cv2.boundingRect(contour)\n",
    "\t\t\t\taspect_ratio = w / float(h)\n",
    "\t\t\t\tarea = w * h\n",
    "\t\t\t\tparent_idx = hierarchy[i][3]\n",
    "\t\t\t\tchild_idx = hierarchy[i][2]\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Use relative area to filter contours after resizing plate to a consistent size\n",
    "\t\t\t\tif 0.1 < aspect_ratio < 2.0 and 70 < area < 800:\n",
    "\t\t\t\t\t# Check if the contour is not a hole (i.e., not a child of another character)\n",
    "\t\t\t\t\t# and if it has no children or its children are significantly smaller\n",
    "\t\t\t\t\tis_valid_character = True\n",
    "\t\t\t\t\tif parent_idx != -1:\n",
    "\t\t\t\t\t\t# If this contour is a child, it might be a hole, so skip it\n",
    "\t\t\t\t\t\tcontinue\n",
    "\t\t\t\t\tif child_idx != -1:\n",
    "\t\t\t\t\t\t# Iterate over all children and check their area\n",
    "\t\t\t\t\t\twhile child_idx != -1:\n",
    "\t\t\t\t\t\t\tchild_area = cv2.contourArea(contours[child_idx])\n",
    "\t\t\t\t\t\t\tif child_area > 0.5 * area:\n",
    "\t\t\t\t\t\t\t\t# If the child area is significant, this means it might not be a hole\n",
    "\t\t\t\t\t\t\t\tis_valid_character = False\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\t\tchild_idx = hierarchy[child_idx][0]  # Get the next child\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tif is_valid_character:\n",
    "\t\t\t\t\t\tbounding_boxes.append((x, y, w, h))\n",
    "\t\t\t\n",
    "\t\t\t# Create a visualization after initial filtering\n",
    "\t\t\tfiltered_visualization = plate.convert(\"RGB\")\n",
    "\t\t\tdraw = ImageDraw.Draw(filtered_visualization)\n",
    "\t\t\tfor x, y, w, h in bounding_boxes:\n",
    "\t\t\t\tdraw.rectangle([x, y, x + w, y + h], outline=\"green\", width=1)\n",
    "\t\t\tplate_visualizations.append(filtered_visualization)\n",
    "\t\t\t\n",
    "\t\t\t# Sort from left to right\n",
    "\t\t\tbounding_boxes = sorted(bounding_boxes, key=lambda box: box[0])\n",
    "\t\t\t\n",
    "\t\t\t# Step 2: Apply the trained model to recognize characters in each segment\n",
    "\t\t\tfor x, y, w, h in bounding_boxes:\n",
    "\t\t\t\tsegment = plate.crop((x, y, x + w, y + h))\n",
    "\t\t\t\tr = w / h\n",
    "\t\t\t\tnew_w, new_h = 60, 80\n",
    "\t\t\t\tsegment = segment.resize((new_w-20, new_h-20))\n",
    "\t\t\t\tsegment_orig = np.array(segment)\n",
    "\t\t\t\tsegment = segment.convert(\"L\")\n",
    "\n",
    "\t\t\t\t# binarialize the image\n",
    "\t\t\t\tbefore = segment.copy()\n",
    "\t\t\t\t_, segment = cv2.threshold(np.array(segment), 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\t\t\t\tsegment = Image.fromarray(segment)\n",
    "\n",
    "\t\t\t\t# place the segment on a black background slightly larger than the original\n",
    "\t\t\t\tbackground = Image.new('L', (new_w, new_h), 255)\n",
    "\t\t\t\toffset = (10, 10)\n",
    "\t\t\t\tbackground.paste(segment, offset)\n",
    "\t\t\t\tsegment = background     \n",
    "\n",
    "\t\t\t\t# Predict with tessaract\n",
    "\t\t\t\t# ocr_result = pytesseract.image_to_data(\n",
    "\t\t\t\t# \tsegment,\n",
    "\t\t\t\t# \tconfig='--psm 10 --oem 3 -c tessedit_char_whitelist=0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ',\n",
    "\t\t\t\t# \toutput_type=pytesseract.Output.DICT\n",
    "\t\t\t\t# )\n",
    "\t\t\t\t# Predict with easyocr\n",
    "\t\t\t\tocr_result = reader.recognize(\n",
    "\t\t\t\t\tnp.array(segment),\n",
    "\t\t\t\t\tallowlist=\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "\t\t\t\t)\n",
    "\t\t\t\tocr_result = {\n",
    "\t\t\t\t\t\"text\": [res[1] for res in ocr_result],\n",
    "\t\t\t\t\t\"conf\": [res[2]*100 for res in ocr_result]\n",
    "\t\t\t\t}\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Filter based on confidence\n",
    "\t\t\t\t# try:\n",
    "\t\t\t\t# \tocr_result['conf'][0]\n",
    "\t\t\t\t# except:\n",
    "\t\t\t\t\t# plt.imshow(segment)\n",
    "\t\t\t\t\t# plt.show()\n",
    "\t\t\t\tconfidences = [float(conf) for conf in ocr_result['conf']]\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Filter blue segments (E parts)\n",
    "\t\t\t\tsegment_orig = cv2.cvtColor(segment_orig, cv2.COLOR_RGB2HSV)\n",
    "\t\t\t\tlower_blue = np.array([100, 50, 50])\n",
    "\t\t\t\tupper_blue = np.array([140, 255, 255])\n",
    "\t\t\t\tblue_mask = cv2.inRange(segment_orig, lower_blue, upper_blue)\n",
    "\t\t\t\tblue_pixel_count = cv2.countNonZero(blue_mask)\n",
    "\t\t\t\ttotal_pixel_count = segment_orig.shape[0] * segment_orig.shape[1]\n",
    "\t\t\t\tblue_ratio = blue_pixel_count / total_pixel_count\n",
    "\t\t\t\tis_blue = blue_ratio > 0.5\n",
    "\n",
    "\t\t\t\t# Filter blobs\n",
    "\t\t\t\teroded = 255 - np.array(segment)\n",
    "\t\t\t\teroded = cv2.erode(eroded, np.ones((3, 3)), iterations=8)\n",
    "\t\t\t\tis_blob = np.count_nonzero(eroded) / (new_w*new_h) > 0.05\n",
    "\n",
    "\t\t\t\tif confidences and max(confidences) >= -1 and not is_blue and not is_blob:\n",
    "\t\t\t\t\trecognized_text = ocr_result['text'][np.argmax(confidences)].strip()\n",
    "\t\t\t\t\tplate_segments.append(segment)\n",
    "\t\t\t\t\tplate_recognized.append((segment, recognized_text, max(confidences), ocr_result, before))\n",
    "\t\t\t\n",
    "\t\t\timg_segments.append(plate_segments)\n",
    "\t\t\timg_visualizations.append(plate_visualizations)\n",
    "\t\t\timg_recognized.append(plate_recognized)\n",
    "\t\tsegments.append(img_segments)\n",
    "\t\tvisualizations.append(img_visualizations)\n",
    "\t\trecognized_characters.append(img_recognized)\n",
    "\treturn segments, visualizations, recognized_characters\n",
    "\n",
    "segments, visualizations, recognized_characters = segment(crops)\n",
    "\n",
    "# Visualization script for debugging\n",
    "def visualize_bounding_boxes(visualizations: List[List[List[Image.Image]]]):\n",
    "\tfor img_vis in visualizations:\n",
    "\t\tfor plate_vis in img_vis:\n",
    "\t\t\tfor vis in plate_vis:\n",
    "\t\t\t\tplt.imshow(vis)\n",
    "\t\t\t\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments, visualizations, recognized_characters = segment(crops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
